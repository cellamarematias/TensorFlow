# üìä Conjunto de Datos: Diabetes
Utilizaremos el conjunto de datos de diabetes, que contiene varias caracter√≠sticas m√©dicas de pacientes y una medida num√©rica de la progresi√≥n de la enfermedad un a√±o despu√©s. Este conjunto de datos es ideal para demostrar c√≥mo una red neuronal puede manejar m√∫ltiples caracter√≠sticas para realizar predicciones.

# üîÑ Flujo del Proceso
Carga y Exploraci√≥n de Datos: Importaremos el conjunto de datos y exploraremos sus caracter√≠sticas.‚Äã

Preprocesamiento: Normalizaremos los datos para mejorar el rendimiento del modelo.‚Äã

Divisi√≥n de Datos: Separaremos los datos en conjuntos de entrenamiento y prueba.‚Äã

Construcci√≥n del Modelo: Crearemos una red neuronal con capas ocultas y el optimizador Adam.‚Äã

Entrenamiento: Entrenaremos el modelo y registraremos el historial de p√©rdida.‚Äã

Evaluaci√≥n y Visualizaci√≥n: Evaluaremos el modelo y visualizaremos los resultados.‚Äã

# üõ†Ô∏è Implementaci√≥n en C√≥digo

# Red Neuronal para Predicci√≥n de Progresi√≥n de Diabetes

A continuaci√≥n, implementaremos una red neuronal utilizando el conjunto de datos de diabetes. Este ejemplo incluye m√∫ltiples caracter√≠sticas por muestra y utiliza el optimizador Adam con varias capas ocultas.

## 1. Importar Librer√≠as Necesarias

```
import numpy as np
import tensorflow as tf
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
```

## 2. Cargar y Explorar el Conjunto de Datos

```
# Cargar el conjunto de datos de diabetes
diabetes = load_diabetes()
X = diabetes.data
y = diabetes.target

# Mostrar informaci√≥n b√°sica sobre los datos
print(f"N√∫mero de muestras: {X.shape[0]}")
print(f"N√∫mero de caracter√≠sticas: {X.shape[1]}")
print(f"Caracter√≠sticas: {diabetes.feature_names}")
```

## 3. Preprocesamiento de Datos

```
# Normalizar las caracter√≠sticas para que tengan media 0 y desviaci√≥n est√°ndar 1
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

## 4. Dividir los Datos en Conjuntos de Entrenamiento y Prueba

```
# Dividir los datos en 80% para entrenamiento y 20% para prueba
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
```

## 5. Construir el Modelo de Red Neuronal

```
# Definir el modelo secuencial
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Capa oculta 1
    tf.keras.layers.Dense(32, activation='relu'),                                   # Capa oculta 2
    tf.keras.layers.Dense(1)                                                       # Capa de salida
])

# Compilar el modelo con el optimizador Adam y la funci√≥n de p√©rdida MAE
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),
              loss='mae',
              metrics=['mae'])
```

## 6. Entrenar el Modelo

```
# Entrenar el modelo con 100 √©pocas y un tama√±o de lote de 16
history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.2, verbose=1)
```

## 7. Evaluar el Modelo

```
# Evaluar el modelo en el conjunto de prueba
test_loss, test_mae = model.evaluate(X_test, y_test)
print(f"Error Absoluto Medio en el conjunto de prueba: {test_mae:.2f}")
```

## 8. Visualizar la P√©rdida Durante el Entrenamiento

```
# Graficar la p√©rdida durante el entrenamiento y la validaci√≥n
plt.plot(history.history['loss'], label='Entrenamiento')
plt.plot(history.history['val_loss'], label='Validaci√≥n')
plt.title('P√©rdida durante el Entrenamiento y Validaci√≥n')
plt.xlabel('√âpocas')
plt.ylabel('P√©rdida (MAE)')
plt.legend()
plt.grid(True)
plt.show()
```

## 9. Realizar una Predicci√≥n

```
# Seleccionar una muestra del conjunto de prueba para predecir
nueva_muestra = X_test[0].reshape(1, -1)
prediccion = model.predict(nueva_muestra)

print(f"Predicci√≥n para la nueva muestra: {prediccion[0][0]:.2f}")
print(f"Valor real: {y_test[0]:.2f}")
```

---

Este ejemplo pr√°ctico te permite ver c√≥mo una red neuronal maneja m√∫ltiples caracter√≠sticas para realizar predicciones. Adem√°s, la visualizaci√≥n de la p√©rdida durante el entrenamiento te ayuda a comprender el proceso de aprendizaje del modelo.
