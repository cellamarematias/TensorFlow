# ğŸš€ Â¿QuÃ© es el Learning Rate (Tasa de Aprendizaje)?

El **learning rate** (o tasa de aprendizaje) es uno de los **hiperparÃ¡metros mÃ¡s importantes** en el entrenamiento de modelos de machine learning, especialmente en redes neuronales.

Es el valor que determina **cuÃ¡nto se actualizan los pesos del modelo** en cada paso del entrenamiento cuando se minimiza la funciÃ³n de pÃ©rdida.

---

## ğŸ§  Â¿CÃ³mo funciona?

Durante el entrenamiento, el modelo ajusta sus pesos para reducir el error (pÃ©rdida). Esto se hace mediante un algoritmo de optimizaciÃ³n (como SGD o Adam). El learning rate controla **el tamaÃ±o de estos ajustes**.

```
peso_nuevo = peso_actual - learning_rate * gradiente
```

---

## ğŸ“Š Ejemplo visual:

ImaginÃ¡ que estÃ¡s bajando una montaÃ±a en bicicleta (querÃ©s llegar al punto mÃ¡s bajo = mÃ­nimo de la pÃ©rdida):

- ğŸ”¹ Un learning rate **muy bajo**: avanzÃ¡s despacio â†’ tarda mucho en llegar.
- ğŸ”¹ Un learning rate **muy alto**: das saltos grandes â†’ podÃ©s pasarte del mÃ­nimo o incluso **divergir**.

---

## âœ… Â¿QuÃ© valores usar?

No hay una Ãºnica respuesta, pero algunos valores comunes:

- 0.01 â†’ valor clÃ¡sico y seguro
- 0.001 â†’ mÃ¡s pequeÃ±o, mÃ¡s preciso, mÃ¡s lento
- 0.1 â†’ agresivo, mÃ¡s rÃ¡pido pero puede ser inestable

Los optimizadores modernos como `Adam` suelen funcionar bien con `learning_rate=0.001`.

---

## ğŸ§ª Â¿DÃ³nde se define?

En Keras / TensorFlow:

```
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
```

En Scikit-learn (cuando aplica), se encuentra en hiperparÃ¡metros como `eta0` o `learning_rate_init`.

---

## ğŸ“Œ Â¿En quÃ© modelos aplica?

- Redes neuronales (ANN, CNN, RNN, etc.)
- Regresiones y modelos lineales con optimizaciÃ³n iterativa
- Modelos de boosting (como XGBoost o LightGBM)
- En general, cualquier modelo que use **gradiente descendente**

---

## ğŸ” Buenas prÃ¡cticas

- ComenzÃ¡ con `0.001` o `0.01`.
- ProbÃ¡ usar **learning rate decay** (bajar el LR a lo largo del tiempo).
- UsÃ¡ herramientas como **Learning Rate Schedulers** o **callbacks** para ajustarlo dinÃ¡micamente.
- GraficÃ¡ la pÃ©rdida durante el entrenamiento para detectar si el learning rate es muy alto (oscilaciones) o muy bajo (muy lento).

---

## ğŸ“‰ Tip visual para elegirlo

Una tÃ©cnica Ãºtil es entrenar el modelo en una sola Ã©poca con diferentes learning rates y graficar la pÃ©rdida para ver cuÃ¡l valor es mÃ¡s estable. Esto se llama **"Learning Rate Finder"**.

---

# ğŸ§ª Experimento Interactivo: Explorando el Learning Rate en una Red Neuronal

Este experimento estÃ¡ diseÃ±ado para visualizar cÃ³mo el **learning rate (tasa de aprendizaje)** afecta al entrenamiento de una red neuronal.

---

## ğŸ“¦ Requisitos

Asegurate de tener TensorFlow y Matplotlib:

```
!pip install tensorflow matplotlib
```

---

## ğŸ“Š Paso 1: Dataset simple

Usaremos un dataset sintÃ©tico con una relaciÃ³n lineal simple.

```
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

# Dataset lineal: y = 3x + 7
X = np.linspace(-10, 10, 100)
y = 3 * X + 7 + np.random.normal(0, 2, size=X.shape)  # con algo de ruido

# Redimensionamos X para que sea una matriz columna
X = X.reshape(-1, 1)
y = y.reshape(-1, 1)
```

---

## ğŸ§  Paso 2: Crear funciÃ³n para entrenar con distinto learning rate

```
def build_and_train_model(learning_rate):
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(10, activation='relu'),
        tf.keras.layers.Dense(1)
    ])
    
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss='mse')

    history = model.fit(X, y, epochs=100, verbose=0)
    return history.history['loss']
```

---

## ğŸ§ª Paso 3: Probar distintos valores de learning rate

```
learning_rates = [1e-2, 1e-3, 1e-4, 1e-5]
losses = {}

for lr in learning_rates:
    print(f"Entrenando con learning rate = {lr}")
    losses[lr] = build_and_train_model(lr)
```

---

## ğŸ“ˆ Paso 4: Graficar resultados

```
plt.figure(figsize=(10, 6))
for lr, loss in losses.items():
    plt.plot(loss, label=f"lr={lr}")

plt.title("PÃ©rdida durante el entrenamiento vs Learning Rate")
plt.xlabel("Ã‰pocas")
plt.ylabel("Loss (MSE)")
plt.legend()
plt.grid(True)
plt.show()
```

---

## ğŸ§¾ Â¿QuÃ© deberÃ­as observar?

- ğŸ”¹ **lr = 1e-2**: puede que sea muy rÃ¡pido o inestable.
- ğŸ”¹ **lr = 1e-3**: suele ser un buen valor base.
- ğŸ”¹ **lr = 1e-4 o 1e-5**: entrenamiento mÃ¡s lento, pero quizÃ¡s mÃ¡s preciso.

---

Â¿QuerÃ©s que lo adaptemos a un dataset real como diabetes, housing, etc.?

