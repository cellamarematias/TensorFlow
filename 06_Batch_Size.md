# ğŸ“¦ Â¿QuÃ© es el Batch Size en el entrenamiento de una red neuronal?

El **batch size** (tamaÃ±o del lote) es la **cantidad de muestras** que el modelo procesa **antes de actualizar sus pesos** durante el entrenamiento.

# ğŸ§  Â¿CÃ³mo funciona?
Cuando entrenÃ¡s un modelo con datos grandes, no se procesan todos a la vez. En cambio, los datos se dividen en pequeÃ±os **"batches"**.

Ejemplo:
- TenÃ©s 1000 muestras.
- Batch size = 32.
- Entonces, el modelo procesarÃ¡ **32 muestras a la vez**, y luego ajustarÃ¡ los pesos.

# ğŸ”„ RelaciÃ³n con Ã©pocas (epochs)
- Una **Ã©poca** es una pasada completa por todos los datos.
- Si tenÃ©s 1000 muestras y batch size = 100, entonces habrÃ¡ **10 pasos** (batches) por Ã©poca.

# âš–ï¸ Â¿QuÃ© batch size elegir?
- **Batch pequeÃ±o (e.g. 8, 16):** mÃ¡s actualizaciones, mÃ¡s ruido, pero puede ayudar a salir de mÃ­nimos locales.
- **Batch grande (e.g. 64, 128):** mÃ¡s estable pero puede consumir mÃ¡s memoria y generalizar menos.

# ğŸ’¡ Por defecto en Keras
Si no lo especificÃ¡s, Keras usarÃ¡ **batch size = 32**.

# ğŸ§ª Ejemplo en cÃ³digo
```
model.fit(X, y, epochs=100, batch_size=16)
```

# ğŸ“Œ En resumen:
- El batch size **controla cuÃ¡ntas muestras se usan antes de actualizar los pesos**.
- Influye en la **velocidad, memoria y calidad** del entrenamiento.
