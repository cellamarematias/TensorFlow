# ğŸ“‰ Â¿QuÃ© es la "pÃ©rdida" (loss) en el entrenamiento de una red neuronal?
La pÃ©rdida (en inglÃ©s, loss) es una medida numÃ©rica de quÃ© tan mal estÃ¡ prediciendo el modelo durante el entrenamiento.

# ğŸ§  Â¿QuÃ© representa?
Es el error promedio entre los valores predichos por el modelo (y_pred) y los valores reales o verdaderos (y_true).

Por ejemplo, si estamos entrenando un modelo que predice:

Entrada: 10

Etiqueta esperada (y): 20

El modelo predice: 16

Entonces el error es: |20 - 16| = 4 (si usamos MAE, error absoluto medio).

# ğŸ”§ Â¿Para quÃ© sirve?
Durante el entrenamiento, el modelo ajusta sus pesos internos para minimizar esta pÃ©rdida. Mientras mÃ¡s baja la pÃ©rdida, mejor el modelo.

# ğŸ“Š Â¿Por quÃ© a veces no es 0?
Porque el modelo estÃ¡ aproximando, no memorizando.

Porque hay ruido en los datos.

Porque todavÃ­a no se ha entrenado suficiente.

# ğŸ“ˆ Â¿CÃ³mo se visualiza?
PodÃ©s graficarla asÃ­:

```
plt.plot(history.history['loss'])
plt.title("PÃ©rdida durante el entrenamiento")
plt.xlabel("Ã‰pocas")
plt.ylabel("Loss (MAE)")
plt.grid(True)
plt.show()
```

# âœ… Tipos comunes de pÃ©rdida:
mae: Error Absoluto Medio (Mean Absolute Error)

mse: Error CuadrÃ¡tico Medio (Mean Squared Error)

binary_crossentropy, categorical_crossentropy: para clasificaciÃ³n

# ğŸ“Œ En resumen:
La pÃ©rdida te dice quÃ© tan bien estÃ¡ aprendiendo tu modelo. Un valor mÃ¡s bajo = mejor rendimiento.